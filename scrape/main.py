import json
import time
import os
from core.scraper import KupiScraper
from core.analytics import analyze_price_history
from core.database import save_product_to_db

def run_scraper_pipeline():
    scraper = KupiScraper()
    
    # Na캜ten칤 kategori칤 ze souboru (pokud existuje)
    categories = []
    cat_file = os.path.join(os.path.dirname(__file__), 'categories.json')
    if os.path.exists(cat_file):
        with open(cat_file, 'r') as f:
            categories = json.load(f)
    else:
        # Fallback, pokud soubor chyb칤
        categories = ["pecivo", "ovoce-a-zelenina", "mlecne-vyrobky-a-vejce"]

    print(f"游 Za캜칤n치m scraping pro {len(categories)} kategori칤.")

    for category in categories:
        print(f"\n游늭 Zpracov치v치m kategorii: {category}")
        
        # 1. St치hnout seznam produkt콢 (jen 1 str치nka pro test, v ostr칠m provozu dej 0 = v코e)
        products_json = scraper.get_discounts_by_category(category, max_pages=1)
        products = json.loads(products_json)
        
        print(f"   -> Nalezeno {len(products)} produkt콢.")

        for i, product in enumerate(products):
            url = product.get('product_url')
            if not url:
                continue

            # 2. St치hnout historii cen (detail produktu)
            # print(f"   [{i+1}/{len(products)}] Stahuji detail: {product['name']}")
            history = scraper.get_price_history(url)
            
            if history:
                # P콏id치me ID produktu k informac칤m (z칤sk치no z detailu)
                product['id'] = history.get('id')
                
                # 3. Anal칳za cen
                metrics = analyze_price_history(history)
                
                # 4. Ulo쬰n칤 do Supabase
                if metrics:
                    save_product_to_db(product, metrics)
            
            # Zpomalen칤 proti zablokov치n칤 (bu캞 hodn칳 robot)
            time.sleep(1.5)

if __name__ == "__main__":
    run_scraper_pipeline()